{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"HelperFunctions\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from UNetModels import UNet\n",
    "from PlotLearningModels import plotLoss\n",
    "from LossFunctions import dice_coef_loss, dice_coef\n",
    "from GenerateTrainingDataSingleChannel import AugmentImages, LoadTrainingData, getTrainingTiles\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageDirectory = '/data/u934/service_imagerie/v_kapoor/from_Ozge_for_curvature/multiple_cells/images/'\n",
    "MaskDirectory = '/data/u934/service_imagerie/v_kapoor/from_Ozge_for_curvature/multiple_cells/masks/'\n",
    "\n",
    "Input_Channels = 1\n",
    "Output_Channels = 1\n",
    "batchsize = 8\n",
    "epochs = 40\n",
    "reload = False\n",
    "##size of image patches for training \n",
    "## note: must be divisible by 32 for UNet \n",
    "\n",
    "PATCH_HEIGHT, PATCH_WIDTH = 1024,1024\n",
    "Num_Samples = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment training data, meaning create more images from the given input images (optional block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero padding all images to the max size found:  2048 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HelperFunctions/Normalize.py:48: UserWarning: Converting data type from 'float64' to ImageJ-compatible 'float32'.\n",
      "  warnings.warn(\"Converting data type from '%s' to ImageJ-compatible '%s'.\" % (t, np.dtype(t_new)))\n",
      "HelperFunctions/Normalize.py:160: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  x = x[slices]\n",
      "HelperFunctions/Normalize.py:48: UserWarning: Converting data type from 'int64' to ImageJ-compatible 'int16'.\n",
      "  warnings.warn(\"Converting data type from '%s' to ImageJ-compatible '%s'.\" % (t, np.dtype(t_new)))\n"
     ]
    }
   ],
   "source": [
    "AugmentImages(ImageDirectory, MaskDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 2048, 2048, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rankfourX, rankfourY = LoadTrainingData(ImageDirectory, MaskDirectory)\n",
    "\n",
    "\n",
    "X, Y = getTrainingTiles(rankfourX, rankfourY,PATCH_HEIGHT,PATCH_WIDTH, Num_Samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on input tensor: (128, 1024, 1024, 1)\n",
      "Validating on input tensor: (32, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_validation, x_train, y_validation, y_train = train_test_split(X, Y, test_size=.8)\n",
    "print('Training on input tensor: {}'.format(x_train.shape))\n",
    "print('Validating on input tensor: {}'.format(x_validation.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples, validate on 32 samples\n",
      "Epoch 1/40\n"
     ]
    }
   ],
   "source": [
    "model_unet = UNet(n_input_channels=Input_Channels, n_output_channels=Output_Channels)\n",
    "model_unet.compile(optimizer='adam', loss=dice_coef_loss, metrics=[dice_coef])\n",
    "history_unet = model_unet.fit(x_train, y_train, batch_size=batchsize, epochs=epochs, \n",
    "                    verbose=1, shuffle=True, \n",
    "                    validation_data=(x_validation, y_validation),\n",
    "                    callbacks=[plotLoss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflowpy3pt5]",
   "language": "python",
   "name": "conda-env-tensorflowpy3pt5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
